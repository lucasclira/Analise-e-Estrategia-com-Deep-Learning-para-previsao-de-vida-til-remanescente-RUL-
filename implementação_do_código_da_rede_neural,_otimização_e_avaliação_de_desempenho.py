# -*- coding: utf-8 -*-
"""Implementação do código da Rede Neural, Otimização e Avaliação de Desempenho.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_nke_vPntPMn0S7yjJ4IaqgB17SUhU70
"""

# Extraia os alvos usando os mesmos índices
y_train_rul = df.loc[X_train.index, 'RUL']
y_val_rul   = df.loc[X_val.index, 'RUL']
y_test_rul  = df.loc[X_test.index, 'RUL']


# Agora os tamanhos batem:
print(X_train.shape, y_train_rul.shape)  # Deve ser igual


# Otimização dos hiperparâmetros e treino
from sklearn.neural_network import MLPRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score


param_grid = {
    'hidden_layer_sizes': [(32,), (64,), (32, 16), (64, 32)],
    'activation': ['relu', 'tanh'],
    'solver': ['adam'],
    'alpha': [0.0001, 0.001],
    'learning_rate_init': [0.001, 0.01]
}


mlp = MLPRegressor(max_iter=200, random_state=42)
grid = GridSearchCV(mlp, param_grid, cv=3, scoring='neg_mean_squared_error', n_jobs=-1)
grid.fit(X_train, y_train_rul)


best_mlp = grid.best_estimator_
best_params = grid.best_params_


y_pred_test = best_mlp.predict(X_test)
y_pred_val = best_mlp.predict(X_val)


mse_test = mean_squared_error(y_test_rul, y_pred_test)
mae_test = mean_absolute_error(y_test_rul, y_pred_test)
r2_test = r2_score(y_test_rul, y_pred_test)


mse_val = mean_squared_error(y_val_rul, y_pred_val)
mae_val = mean_absolute_error(y_val_rul, y_pred_val)
r2_val = r2_score(y_val_rul, y_pred_val)