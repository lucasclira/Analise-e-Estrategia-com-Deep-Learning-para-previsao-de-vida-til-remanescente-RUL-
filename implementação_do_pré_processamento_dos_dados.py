# -*- coding: utf-8 -*-
"""Implementação do Pré Processamento dos Dados.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1byWG09Qr5SKHaLtNEtte_hC0ZhnXxiry
"""

# Importação das bibliotecas
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from imblearn.over_sampling import SMOTE


# 2. Definição dos alvos
# RUL: calcular o número de ciclos até a próxima falha para cada linha
df = df.sort_values('udi').reset_index(drop=True)
rul = []
last_failure = None
falha_indices = df.index[df['falha'] == 1].tolist()
next_failure_idx = 0


for idx in range(len(df)):
    while next_failure_idx < len(falha_indices) and idx > falha_indices[next_failure_idx]:
        next_failure_idx += 1
    if next_failure_idx < len(falha_indices):
        rul.append(falha_indices[next_failure_idx] - idx)
    else:
        rul.append(len(df) - idx)
df['RUL'] = rul


# 3. Separação de features (excluindo identificadores e alvos)
alvos = ['falha', 'RUL']
features = [col for col in df.select_dtypes(include=[np.number]).columns if col not in ['udi'] + alvos]


# 4. Padronização/normalização das variáveis
scaler = StandardScaler()
df[features] = scaler.fit_transform(df[features])


# 5. Divisão temporal dos dados em treino, validação e teste
train_frac = 0.7
val_frac = 0.15


n = len(df)
train_end = int(n * train_frac)
val_end = int(n * (train_frac + val_frac))


X = df[features]
y = df['falha']


X_train = X.iloc[:train_end]
y_train = y.iloc[:train_end]
X_val = X.iloc[train_end:val_end]
y_val = y.iloc[train_end:val_end]
X_test = X.iloc[val_end:]
y_test = y.iloc[val_end:]


# 6. Balanceamento de classes com SMOTE
smote = SMOTE(random_state=0)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)