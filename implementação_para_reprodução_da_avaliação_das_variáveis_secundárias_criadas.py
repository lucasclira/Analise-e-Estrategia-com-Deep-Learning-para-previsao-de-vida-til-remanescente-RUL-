# -*- coding: utf-8 -*-
"""Implementação para Reprodução da Avaliação das Variáveis Secundárias Criadas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yKi7aTqTTSgdQPEOhxHV2WicXDPTM1M2
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np


# Separando features (X) e target (y)
# Excluímos 'udi', 'RUL', e as novas features que podem ter NaNs ou não são diretamente usadas como features de ponto (como FFT e lags brutos)
# Incluímos as features originais e as features agregadas/criadas que são numéricas.
# Vamos ser mais seletivos e incluir apenas as colunas numéricas (exceto 'udi' e 'RUL')
X = df.select_dtypes(include=np.number).drop(columns=['udi', 'RUL', 'falha'], errors='ignore')
y = df['falha']


# Removendo colunas com NaN que possam ter sido criadas (apesar do dropna anterior, é bom verificar)
# E removendo colunas com variação zero (constantes)
X = X.dropna(axis=1, how='all') # Remove colunas onde todos os valores são NaN (should be handled by dropna earlier)
X = X.loc[:, X.nunique() > 1] # Remove colunas constantes


# Dividindo os dados em treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


# Criando e treinando o modelo Decision Tree
dt = DecisionTreeClassifier(random_state=42)
dt.fit(X_train, y_train)


# Obtendo a importância das features
importance = dt.feature_importances_


# Criando um DataFrame para visualizar a importância
feature_importance_df = pd.DataFrame({
    'Feature': X.columns,
    'Importance': importance
})


# Ordenando por importância e pegando as 5 mais importantes
top_5_features = feature_importance_df.sort_values(by='Importance', ascending=False).head(5)


print("As 5 features mais importantes para prever 'falha':")
print(top_5_features)


# Opcional: Visualizar as 5 features mais importantes
plt.figure(figsize=(10, 6))
sns.barplot(x='Importance', y='Feature', data=top_5_features, palette='viridis')
plt.title('Top 5 Feature Importance (Decision Tree) para Falha')
plt.xlabel('Importância')
plt.ylabel('Feature')
plt.tight_layout()
plt.show()